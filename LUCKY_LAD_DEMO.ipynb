{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e545d-f5e4-46a3-836c-8c2e12322969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:\\\\Users\\\\cjcre\\\\Downloads\\\\application_default_credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722ace2-44ee-423f-b9c5-762a164a9e2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install google-cloud-documentai google-api-python-client google-auth-httplib2 google-auth-oauthlib pandas vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd064ce7-62bc-4abc-ad60-f41c19407ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email.utils import parsedate_to_datetime\n",
    "from datetime import datetime\n",
    "from google.cloud import documentai\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "from imaplib import IMAP4_SSL\n",
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    GenerativeModel,\n",
    "    SafetySetting,)\n",
    "import json\n",
    "project_id = \"invoiceprocessing-450716\"\n",
    "location = \"us\"\n",
    "processor_id = \"5486fff89ef396e2\"\n",
    "mime_type = \"application/pdf\"\n",
    "field_mask = \"text,entities,pages.pageNumber\"\n",
    "processor_version_id = \"57f4f1dda43d5c50\"\n",
    "def get_gmail_service(username, password):\n",
    "    try:\n",
    "        mail = IMAP4_SSL(\"imap.gmail.com\")\n",
    "        mail.login(username, password)\n",
    "        mail.select(\"inbox\")\n",
    "        return mail\n",
    "    except IMAP4_SSL.error as e:\n",
    "        print(f\"IMAP Error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting Gmail service: {e}\")\n",
    "        return None\n",
    "def process_document_from_memory(\n",
    "    image_content,\n",
    "    mime_type,\n",
    "    project_id,\n",
    "    location,\n",
    "    processor_id,\n",
    "    field_mask=None,\n",
    "    processor_version_id=None,):\n",
    "    opts = ClientOptions(api_endpoint=f\"{location}-documentai.googleapis.com\")\n",
    "    client = documentai.DocumentProcessorServiceClient(client_options=opts)\n",
    "    if processor_version_id:\n",
    "        name = client.processor_version_path(\n",
    "            project_id, location, processor_id, processor_version_id)\n",
    "    else:\n",
    "        name = client.processor_path(project_id, location, processor_id)\n",
    "    raw_document = documentai.RawDocument(content=image_content, mime_type=mime_type)\n",
    "    process_options = documentai.ProcessOptions(\n",
    "        individual_page_selector=documentai.ProcessOptions.IndividualPageSelector(\n",
    "            pages=[1]))\n",
    "    request = documentai.ProcessRequest(\n",
    "        name=name,\n",
    "        raw_document=raw_document,\n",
    "        field_mask=field_mask,\n",
    "        process_options=process_options,)\n",
    "    result = client.process_document(request=request)\n",
    "    document = result.document\n",
    "    return document\n",
    "def process_email(gmail_service, msg, num, label_name):\n",
    "    date_str = msg[\"Date\"]\n",
    "    email_datetime = parsedate_to_datetime(date_str) if date_str else datetime.now()\n",
    "    extracted_data = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_maintype() == \"multipart\":\n",
    "            continue\n",
    "        if part.get(\"Content-Disposition\") is None:\n",
    "            continue\n",
    "        filename = part.get_filename()\n",
    "        if filename and filename.lower().endswith(\".pdf\"):\n",
    "            payload = part.get_payload(decode=True)\n",
    "            pdf_title_text = \"No Title Found\"\n",
    "            try:\n",
    "                document = process_document_from_memory(\n",
    "                    image_content=payload,\n",
    "                    mime_type=\"application/pdf\",\n",
    "                    project_id=project_id,\n",
    "                    location=location,\n",
    "                    processor_id=processor_id,\n",
    "                    field_mask=\"text\",\n",
    "                    processor_version_id=processor_version_id,\n",
    "                )\n",
    "                if document.text:\n",
    "                    pdf_title_text = \" \".join(document.text.split()[:10]) + \"...\"\n",
    "                text = document.text\n",
    "                entities = document.entities\n",
    "                extracted_entities = {}\n",
    "                for entity in entities:\n",
    "                    extracted_entities[entity.type_] = entity.mention_text\n",
    "                document_data = {\n",
    "                    \"text\": text,\n",
    "                    \"entities\": [\n",
    "                        {\"type_\": e.type_, \"mention_text\": e.mention_text} for e in entities],\n",
    "                }\n",
    "                extracted_data.append(\n",
    "                    {\n",
    "                        \"filename\": filename,\n",
    "                        \"email_datetime\": email_datetime,\n",
    "                        \"text\": text,\n",
    "                        \"entities\": extracted_entities,\n",
    "                        \"document_json\": json.dumps(document_data),\n",
    "                        \"gmail_search_query\": f\"in:inbox \\\"{pdf_title_text}\\\"\",\n",
    "                    }\n",
    "                )\n",
    "                print(f\"Extracted from {filename}: {text[:100]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    try:\n",
    "        status, data = gmail_service.store(num, \"+X-GM-LABELS\", label_name)\n",
    "        if status == \"OK\":\n",
    "            print(f\"Applied label '{label_name}' to email {num}\")\n",
    "        else:\n",
    "            print(f\"Failed to apply label '{label_name}' to email {num}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying label: {e}\")\n",
    "    print(f\"Processed email from {email_datetime}\")\n",
    "    return extracted_data\n",
    "def process_gmail_pdfs(username, password):\n",
    "    gmail_service = get_gmail_service(username, password)\n",
    "    if gmail_service is None:\n",
    "        return\n",
    "    all_extracted_data = []\n",
    "    try:\n",
    "        _, data = gmail_service.search(None, \"UNSEEN\", \"ALL\")\n",
    "        mail_ids = data[0]\n",
    "        id_list = mail_ids.split()\n",
    "        now = datetime.now()\n",
    "        label_name = now.strftime(\"%B_%Y_Invoices\")\n",
    "        status, data = gmail_service.list()\n",
    "        if status == \"OK\":\n",
    "            label_exists = False\n",
    "            for item in data:\n",
    "                if label_name in str(item):\n",
    "                    label_exists = True\n",
    "                    break\n",
    "            if not label_exists:\n",
    "                status, data = gmail_service.create('\"' + label_name + '\"')\n",
    "                if status == \"OK\":\n",
    "                    print(f\"Created label '{label_name}'\")\n",
    "                else:\n",
    "                    print(f\"Failed to create label '{label_name}'\")\n",
    "        else:\n",
    "            print(\"Failed to list labels.\")\n",
    "        for num in id_list:\n",
    "            _, data = gmail_service.fetch(num, \"(RFC822)\")\n",
    "            for response_part in data:\n",
    "                if isinstance(response_part, tuple):\n",
    "                    msg = email.message_from_bytes(response_part[1])\n",
    "                    extracted_data = process_email(\n",
    "                        gmail_service, msg, num, label_name)\n",
    "                    all_extracted_data.extend(extracted_data)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        try:\n",
    "            gmail_service.close()\n",
    "            gmail_service.logout()\n",
    "        except:\n",
    "            pass\n",
    "    return all_extracted_data\n",
    "def display_extracted_data(extracted_data):\n",
    "    if not extracted_data:\n",
    "        print(\"No data extracted from emails.\")\n",
    "        return\n",
    "    data_list = []\n",
    "    for data in extracted_data:\n",
    "        data_row = {\n",
    "            \"Filename\": data[\"filename\"],\n",
    "            \"Email Date\": data[\"email_datetime\"],\n",
    "            \"Text\": data[\"text\"][:200] + \"...\",}\n",
    "        data_row.update(data[\"entities\"])\n",
    "        data_row[\"Document JSON\"] = data[\n",
    "            \"document_json\"]\n",
    "        data_list.append(data_row)\n",
    "    df = pd.DataFrame(data_list)\n",
    "    display(HTML(df.to_html(index=False)))\n",
    "def multiturn_generate_content(document_json_string):\n",
    "    vertexai.init(\n",
    "        project=\"invoiceprocessing-450716\",\n",
    "        location=\"us-central1\",\n",
    "        api_endpoint=\"aiplatform.googleapis.com\",)\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-pro-002\", system_instruction=[si_text1])\n",
    "    chat = model.start_chat()\n",
    "    try:\n",
    "        response = chat.send_message(\n",
    "            [msg1_text1.replace(\"[Value from Doc AI]\", document_json_string)],\n",
    "            generation_config=generation_config,\n",
    "            safety_settings=safety_settings,)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Vertex AI: {e}\")\n",
    "        return None\n",
    "msg1_text1 = \"\"\"General Information Verification:\n",
    "\\\"Google Document AI extracted the Invoice Number as '[Value from Doc AI]'. Please verify this against the attached PDF. If it matches, respond 'Match'. If not, provide the correct Invoice Number from the PDF.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Invoice Date as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Invoice Date.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Due Date as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Due Date.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Vendor Name as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Vendor Name.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Bill To Name as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Bill To Name.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Ship To Name as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Ship To Name.\\\" (Example source )\n",
    "Financial Details Verification:\n",
    "\\\"Google Document AI extracted the Subtotal as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Subtotal.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Sales Tax as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Sales Tax amount.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Total Amount Due as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Total Amount Due.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Balance Due as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Balance Due.\\\" (Example source )\n",
    "Line Item Verification (Repeat for each relevant line item):\n",
    "\\\"For the line item where Google Document AI extracted the Description as '[Value from Doc AI]', verify this description against the PDF. If match, respond 'Match'. If not, provide the correct Description.\\\" (Example source )\n",
    "\\\"For the line item with description '[Verified Description from PDF]', Google Document AI extracted the Quantity as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Quantity.\\\" (Example source )\n",
    "\\\"For the line item with description '[Verified Description from PDF]', Google Document AI extracted the Unit Price as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Unit Price.\\\" (Example source )\n",
    "\\\"For the line item with description '[Verified Description from PDF]', Google Document AI extracted the Total Line Amount as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Total Line Amount.\\\" (Example source )\n",
    "Statement Specific Verification:\n",
    "\\\"Google Document AI extracted the Statement Date as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Statement Date.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the final Amount Due (from the summary/aging) as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Amount Due.\\\" (Example source )\"\"\"\n",
    "si_text1 = \"\"\"You are an AI assistant functioning as a data validation and verification specialist. Your task is to compare data extracted by Google Document AI against the original source document (invoice or statement PDF).\n",
    "Your Task:\n",
    "You will be provided with a specific data field (e.g., \\\"Invoice Number\\\") and the value extracted for that field by Google Document AI.\n",
    "You will also be given access to, or the text content of, the original source PDF document (invoice or statement).\n",
    "Carefully examine the source PDF document to locate the specified data field.\n",
    "Compare the value present in the PDF document with the value provided by Google Document AI.\n",
    "Verification:If the value from Google Document AI matches the value in the PDF, confirm the match.\n",
    "If the value from Google Document AI does not match the value in the PDF, provide the correct value as it appears in the PDF.\n",
    "If the specified data field cannot be found in the PDF document, state that it is not present.\n",
    "Focus solely on verifying the provided data points against the visual information in the PDF. Do not infer, calculate, or validate information beyond this comparison.\n",
    "I need the vertex ai response to have standardized names, so for invoice number always use invoice number throughout all the documents. I want all the headers to be standardized.\n",
    "I want to see the value found instead of match.\n",
    "For line item verification, I want the name of the line item to be Description 1, Description 2, and so on with there also be a matching Quantity 1, Unit Price 1, Total Amount 1.\"\"\"\n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 2048,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.95,}\n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF,),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF,),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF,),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF,),]\n",
    "if __name__ == \"__main__\":\n",
    "    username = \"lucky.lad.test.df@gmail.com\"\n",
    "    password = \"elsu cbfl urqv ahok\"\n",
    "    extracted_data = process_gmail_pdfs(username, password)\n",
    "    vertex_ai_responses = {}\n",
    "    cleaned_responses = {}\n",
    "    if extracted_data:\n",
    "        for i, data in enumerate(extracted_data):\n",
    "            document_json_string = data[\"document_json\"]\n",
    "            vertex_ai_response = multiturn_generate_content(document_json_string)\n",
    "            if vertex_ai_response:\n",
    "                response_variable_name = f\"vertex_ai_response_{i + 1}\"\n",
    "                vertex_ai_responses[response_variable_name] = vertex_ai_response\n",
    "                print(f\"Vertex AI Response for document {i + 1}:\\n\")\n",
    "            else:\n",
    "                print(f\"Vertex AI call failed for document {i + 1}\")\n",
    "    else:\n",
    "        print(\"No data extracted from emails.\")\n",
    "    for response_name, response_content in vertex_ai_responses.items():\n",
    "        cleaned_response = \"\\n\".join(line.replace(\"Value found: \", \"\").replace(\"* \", \"\").lstrip(\"*\") for line in response_content.splitlines())\n",
    "        cleaned_response = \"\\n\".join(line.replace(\"*\", \"\").strip() for line in cleaned_response.splitlines())\n",
    "        cleaned_responses[response_name] = cleaned_response\n",
    "        print(f\"--- Cleaned {response_name} ---\")\n",
    "        print()\n",
    "    dataframes = {}\n",
    "    df_counter = 1\n",
    "    prefixes_to_remove = [\n",
    "        \"GeneralInformationVerification_\",\n",
    "        \"FinancialDetailsVerification_\",\n",
    "        \"StatementSpecificVerification_\",\n",
    "        \"LineItemVerification_\",]\n",
    "    for i, (response_name, response_content) in enumerate(cleaned_responses.items()):\n",
    "        data = {}\n",
    "        current_section = None\n",
    "        line_item_counter = 1\n",
    "        gmail_search_query = None\n",
    "        pdf_filename = None\n",
    "        if extracted_data and i < len(extracted_data):\n",
    "            gmail_search_query = extracted_data[i].get(\"gmail_search_query\")\n",
    "            pdf_filename = extracted_data[i].get(\"filename\")\n",
    "        for line in response_content.splitlines():\n",
    "            line = line.strip()\n",
    "            if line.endswith(\"Verification:\"):\n",
    "                current_section = line[:-1].strip()\n",
    "                if current_section not in data:\n",
    "                    data[current_section] = {}\n",
    "                line_item_counter = 1\n",
    "            elif \":\" in line:\n",
    "                key, value = line.split(\":\", 1)\n",
    "                key = key.strip()\n",
    "                value = value.strip()\n",
    "                if current_section == \"Line Item Verification\":\n",
    "                    if key.startswith(\"Description\"):\n",
    "                        data[current_section][f\"Description {line_item_counter}\"] = value\n",
    "                    elif key.startswith(\"Quantity\"):\n",
    "                        data[current_section][f\"Quantity {line_item_counter}\"] = value\n",
    "                    elif key.startswith(\"Unit Price\"):\n",
    "                        data[current_section][f\"Unit Price {line_item_counter}\"] = value\n",
    "                    elif key.startswith(\"Total Amount\"):\n",
    "                        data[current_section][f\"Total Amount {line_item_counter}\"] = value\n",
    "                        line_item_counter += 1\n",
    "                    else:\n",
    "                        data[current_section][key] = value\n",
    "                else:\n",
    "                    data[current_section][key] = value\n",
    "        df_data = {}\n",
    "        for section, values in data.items():\n",
    "            for key, value in values.items():\n",
    "                df_data[f\"{section.replace(' ', '')}_{key.replace(' ', '')}\"] = value\n",
    "        df_data[\"PDF Filename\"] = pdf_filename\n",
    "        df = pd.DataFrame([df_data])\n",
    "        new_columns = {}\n",
    "        for col in df.columns:\n",
    "            new_col = col\n",
    "            for prefix in prefixes_to_remove:\n",
    "                new_col = new_col.replace(prefix, \"\")\n",
    "            new_columns[col] = new_col\n",
    "        df = df.rename(columns=new_columns)\n",
    "        df_name = f\"df{df_counter}\"\n",
    "        globals()[df_name] = df\n",
    "        dataframes[response_name] = globals()[df_name]\n",
    "        df_counter += 1\n",
    "    final_df = pd.DataFrame()\n",
    "    for df_name, df in dataframes.items():\n",
    "        if final_df.empty:\n",
    "            final_df = df\n",
    "        else:\n",
    "            final_df = pd.concat([final_df, df], ignore_index=True, sort=False)\n",
    "    print(\"\\n--- Final Concatenated DataFrame (final_df) ---\")\n",
    "final_df = final_df.rename(columns={'AmountDue(fromthesummary/aging)': 'AmountDuefromthesummary_aging'})\n",
    "final_df = final_df.rename(columns={'PDF Filename': 'PDFFilename'})\n",
    "final_df = final_df.rename(columns={'FinalAmountDue(fromthesummary/aging)': 'FinalamountDuefromthesummary_aging'})\n",
    "final_df = final_df.astype(str)\n",
    "print(final_df)\n",
    "import snowflake.connector\n",
    "SNOWFLAKE_ACCOUNT = \"ifb67743.us-east-1\"\n",
    "SNOWFLAKE_USER = \"DF_SVC_US_WELLS_UPDATE\"\n",
    "SNOWFLAKE_PASSWORD = \"g]=V41$;2(Aj3s#3\"\n",
    "SNOWFLAKE_DATABASE = \"OCCLUSION\"\n",
    "SNOWFLAKE_SCHEMA = \"WELLS\"\n",
    "SNOWFLAKE_WAREHOUSE = \"COMPUTE_WH\"\n",
    "SNOWFLAKE_TABLE = \"LUCKY_LAD_INVOICE_PROCESSOR\"\n",
    "def add_missing_columns(df: pd.DataFrame):\n",
    "    ctx = None\n",
    "    cs = None\n",
    "    try:\n",
    "        ctx = snowflake.connector.connect(\n",
    "            account=SNOWFLAKE_ACCOUNT,\n",
    "            user=SNOWFLAKE_USER,\n",
    "            password=SNOWFLAKE_PASSWORD,\n",
    "            database=SNOWFLAKE_DATABASE,\n",
    "            schema=SNOWFLAKE_SCHEMA,\n",
    "            warehouse=SNOWFLAKE_WAREHOUSE)\n",
    "        cs = ctx.cursor()\n",
    "        df_columns = set(df.columns)\n",
    "        table_columns_sql = f\"\"\"\n",
    "        SELECT column_name\n",
    "        FROM {SNOWFLAKE_DATABASE}.INFORMATION_SCHEMA.COLUMNS\n",
    "        WHERE table_catalog = '{SNOWFLAKE_DATABASE}'\n",
    "          AND table_schema = '{SNOWFLAKE_SCHEMA}'\n",
    "          AND table_name = '{SNOWFLAKE_TABLE}'\n",
    "        \"\"\"\n",
    "        cs.execute(table_columns_sql)\n",
    "        existing_columns = {row[0].upper() for row in cs.fetchall()}\n",
    "        new_columns_to_add = df_columns - existing_columns\n",
    "        for col in new_columns_to_add:\n",
    "            alter_table_sql = f\"\"\"\n",
    "            ALTER TABLE {SNOWFLAKE_DATABASE}.{SNOWFLAKE_SCHEMA}.{SNOWFLAKE_TABLE}\n",
    "            ADD COLUMN {col} VARCHAR;\n",
    "            \"\"\"\n",
    "            try:\n",
    "                cs.execute(alter_table_sql)\n",
    "                print(f\"Added column '{col}' to table '{SNOWFLAKE_TABLE}'.\")\n",
    "            except snowflake.connector.errors.ProgrammingError as e:\n",
    "                print(f\"Error adding column '{col}': {e}\")\n",
    "            except snowflake.connector.errors.DatabaseError as e:\n",
    "                print(f\"Database Error adding column '{col}': {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"General error adding column '{col}': {e}\")\n",
    "        ctx.commit()\n",
    "    except snowflake.connector.errors.Error as e:\n",
    "        print(f\"Snowflake Error in add_missing_columns: {e}\")\n",
    "    finally:\n",
    "        if cs:\n",
    "            cs.close()\n",
    "        if ctx:\n",
    "            ctx.close()\n",
    "def add_dataframe_to_snowflake(df: pd.DataFrame):\n",
    "    ctx = None\n",
    "    cs = None\n",
    "    try:\n",
    "        ctx = snowflake.connector.connect(\n",
    "            account=SNOWFLAKE_ACCOUNT,\n",
    "            user=SNOWFLAKE_USER,\n",
    "            password=SNOWFLAKE_PASSWORD,\n",
    "            database=SNOWFLAKE_DATABASE,\n",
    "            schema=SNOWFLAKE_SCHEMA,\n",
    "            warehouse=SNOWFLAKE_WAREHOUSE)\n",
    "        cs = ctx.cursor()\n",
    "        add_missing_columns(df)\n",
    "        columns = \", \".join(df.columns)\n",
    "        placeholders = \", \".join([\"%s\"] * len(df.columns))\n",
    "        sql = f\"INSERT INTO {SNOWFLAKE_DATABASE}.{SNOWFLAKE_SCHEMA}.{SNOWFLAKE_TABLE} ({columns}) VALUES ({placeholders})\"\n",
    "        for row in df.itertuples(index=False):\n",
    "            try:\n",
    "                cs.execute(sql, row)\n",
    "            except snowflake.connector.errors.ProgrammingError as e:\n",
    "                print(f\"Error inserting row: {row}\")\n",
    "                print(f\"Snowflake Programming Error: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"General error inserting row: {row}\")\n",
    "                print(f\"Python Error: {e}\")\n",
    "        ctx.commit()\n",
    "        print(f\"Successfully added {len(df)} rows to {SNOWFLAKE_DATABASE}.{SNOWFLAKE_SCHEMA}.{SNOWFLAKE_TABLE}\")\n",
    "    except snowflake.connector.errors.Error as e:\n",
    "        print(f\"Snowflake Error in add_dataframe_to_snowflake: {e}\")\n",
    "    finally:\n",
    "        if ctx:\n",
    "            cs.close()\n",
    "            ctx.close()\n",
    "if __name__ == \"__main__\":\n",
    "    add_dataframe_to_snowflake(final_df)\n",
    "    print(\"Script finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b4d55-9511-484c-b687-a4c17bd298ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg1_text1 = \"\"\"General Information Verification:\n",
    "\\\"Google Document AI extracted the Invoice Number as '[Value from Doc AI]'. Please verify this against the attached PDF. If it matches, respond 'Match'. If not, provide the correct Invoice Number from the PDF.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Invoice Date as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Invoice Date.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Due Date as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Due Date.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Vendor Name as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Vendor Name.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Bill To Name as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Bill To Name.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Ship To Name as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Ship To Name.\\\" (Example source )\n",
    "Financial Details Verification:\n",
    "\\\"Google Document AI extracted the Subtotal as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Subtotal.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Sales Tax as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Sales Tax amount.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Total Amount Due as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Total Amount Due.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the Balance Due as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Balance Due.\\\" (Example source )\n",
    "Line Item Verification (Repeat for each relevant line item):\n",
    "\\\"For the line item where Google Document AI extracted the Description as '[Value from Doc AI]', verify this description against the PDF. If match, respond 'Match'. If not, provide the correct Description.\\\" (Example source )\n",
    "\\\"For the line item with description '[Verified Description from PDF]', Google Document AI extracted the Quantity as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Quantity.\\\" (Example source )\n",
    "\\\"For the line item with description '[Verified Description from PDF]', Google Document AI extracted the Unit Price as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Unit Price.\\\" (Example source )\n",
    "\\\"For the line item with description '[Verified Description from PDF]', Google Document AI extracted the Total Line Amount as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Total Line Amount.\\\" (Example source )\n",
    "Statement Specific Verification:\n",
    "\\\"Google Document AI extracted the Statement Date as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Statement Date.\\\" (Example source )\n",
    "\\\"Google Document AI extracted the final Amount Due (from the summary/aging) as '[Value from Doc AI]'. Verify against the PDF. If match, respond 'Match'. If not, provide the correct Amount Due.\\\" (Example source )\"\"\"\n",
    "si_text1 = \"\"\"You are an AI assistant functioning as a data validation and verification specialist. Your task is to compare data extracted by Google Document AI against the original source document (invoice or statement PDF).\n",
    "Your Task:\n",
    "You will be provided with a specific data field (e.g., \\\"Invoice Number\\\") and the value extracted for that field by Google Document AI.\n",
    "You will also be given access to, or the text content of, the original source PDF document (invoice or statement).\n",
    "Carefully examine the source PDF document to locate the specified data field.\n",
    "Compare the value present in the PDF document with the value provided by Google Document AI.\n",
    "Verification:If the value from Google Document AI matches the value in the PDF, confirm the match.\n",
    "If the value from Google Document AI does not match the value in the PDF, provide the correct value as it appears in the PDF.\n",
    "If the specified data field cannot be found in the PDF document, state that it is not present.\n",
    "Focus solely on verifying the provided data points against the visual information in the PDF. Do not infer, calculate, or validate information beyond this comparison.\n",
    "I need the vertex ai response to have standardized names, so for invoice number always use invoice number throughout all the documents. I want all the headers to be standardized.\n",
    "I want to see the value found instead of match.\n",
    "For line item verification, I want the name of the line item to be Description 1, Description 2, and so on with there also be a matching Quantity 1, Unit Price 1, Total Amount 1.\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
